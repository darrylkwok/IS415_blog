---
title: "Take-Home Exercise 2"
description: |
  A short description of the post.
author:
  - name: Darryl Kwok
    url: https://example.com/darrylkwok
date: 09-15-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE, eval=TRUE, echo=TRUE, message=FALSE, error=FALSE, fig.retina=3}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

## Installing and launching the R packages

```{r}
packages = c('sp', 'rgdal', 'spNetwork', 'tmap', 'maptools', 'sf', 'raster', 'spatstat', 'tidyverse', 'plotly', 'ggthemes')
for (p in packages){
if(!require(p, character.only = T)){
install.packages(p)
}
library(p,character.only = T)
}
```



# Data

## Import Geospatial Data

```{r}
train_services_sf <- st_read(dsn="data/geospatial", layer="MRTLRTStnPtt")
mpsz_sf <- st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
sg_sf <- st_read(dsn = "data/geospatial", layer="CostalOutline")
```

## Geospatial Data Preparation

### Check the detailed information of the geospatial data

```{r}
st_crs(train_services_sf)
st_crs(mpsz_sf)
st_crs(sg_sf)
```

We can see from these 3 st_crs() outputs that, the projections are in SVY21, however the EPSG code is 9001. The correct EPSG code is 3414. 

Therefore, we will assign the correct EPSG code.

```{r}
train_services_sf <- st_set_crs(train_services_sf, 3414)
mpsz_sf <- st_set_crs(mpsz_sf, 3414)
sg_sf <- st_set_crs(sg_sf, 3414)
```

Check the crs of the 3 geospatial data again to confirm the changes

```{r}
st_crs(train_services_sf)
st_crs(mpsz_sf)
st_crs(sg_sf)
```

Check if the geometries are valid for the train_services_sf 

```{r}
length(which(st_is_valid(train_services_sf) == FALSE))
```

From the above output, we can see that there are no invalid geometries for the train_services_sf

Check if the geometries are valid for the mpsz_sf

```{r}
length(which(st_is_valid(mpsz_sf) == FALSE))
```

From the above output, we can see that there are 9 invalid geometries in the mpsz data

Therefore, we will handle the invalid geometries and check if the changes are made.

```{r}
mpsz_sf <- st_make_valid(mpsz_sf)
length(which(st_is_valid(mpsz_sf) == FALSE))
```

Check if the geometries are valid for the sg_sf

```{r}
length(which(st_is_valid(sg_sf) == FALSE))
```

From the above output, we can see that there are 1 invalid geometries in the sg data

Therefore, we will handle the invalid geometries and check if the changes are made.

```{r}
sg_sf <- st_make_valid(sg_sf)
length(which(st_is_valid(sg_sf) == FALSE))
```


### Visualise the Location of the Train Services on the Singapore Map

```{r}
tmap_mode('view')

tm_shape(train_services_sf) +
  tm_dots(col="red", size=0.1)

tmap_mode('plot')
```


## Import Aspatial Data

```{r}
june_2019 <- read_csv("data/aspatial/30062019.csv")
june_2021 <- read_csv("data/aspatial/30062021.csv")
hotels <- read_csv("data/aspatial/hotels.csv")
tourism <- read_csv("data/aspatial/tourism.csv")
``` 

## Aspatial Data Preparation

### Learn more about each of the aspatial datasets

```{r}
glimpse(june_2019)
```

```{r}
glimpse(june_2021)
```

```{r}
glimpse(hotels)
```

```{r}
glimpse(tourism)
```

After using the glimpse() function on all the aspatial data, there are a few observations:

  - All of the data uses Longitude and Latitude or Lng and Lat for the column names
  - The Longitude and Latitude of all the data are projected in the 4326 projection system
  

### Check if there are rows that have missing values in june_2019 dataframe longtitude or latitude columns

```{r}
sum(is.na(june_2019$latitude))
sum(is.na(june_2019$longitude))
```

### Check if there are rows that have missing values in june_2021 dataframe longtitude or latitude columns

```{r}
sum(is.na(june_2021$latitude))
sum(is.na(june_2021$longitude))
```

### Check if there are rows that have missing values in hotels dataframe longtitude or latitude columns

```{r}
sum(is.na(hotels$Lng))
sum(is.na(hotels$Lat))
```

### Check if there are rows that have missing values in tourism dataframe longtitude or latitude columns

There are 2 geographic coordinates in the tourism dataframe

```{r}
sum(is.na(tourism$LONGTITUDE))
sum(is.na(tourism$LATITUDE))
```
```{r}
sum(is.na(tourism$Lat))
sum(is.na(tourism$Lng))
```

We can see that the LONGTITUDE and LATITUDE columns contains missing values but the Lat and Lng columns contains no missing values.

### Extract the row that contains missing values in the LONGTITUDE and LATITUDE columns

```{r}
tourism[(is.na(tourism$LONGTITUDE) | tourism$LONGTITUDE=="" | is.na(tourism$LATITUDE) | tourism$LATITUDE == ""), ]
```

Although Crusises from Singapore is a tourism activity, it does not belong to a specific location on the map. Therefore we will remove it from the dataframe. This is because having 0,0 coordinates can many different meanings in Geospatial Data

```{r}
tourism <- tourism[!(is.na(tourism$LONGTITUDE) | tourism$LONGTITUDE=="" | is.na(tourism$LATITUDE) | tourism$LATITUDE == ""), ]
```

Check if the row is removed from the dataframe

```{r}
tourism[(is.na(tourism$LONGTITUDE) | tourism$LONGTITUDE=="" | is.na(tourism$LATITUDE) | tourism$LATITUDE == ""), ]
```


### Convert the R Dataframes into sf objects and transform the coordinate projection system

Steps Taken:

  - Convert the R Dataframes into an sf object by defining the columns and the projection system
  - Then transform the projection system to the correct one

```{r}
june_2019_sf <- st_as_sf(june_2019, coords = c("longitude", "latitude"), crs = 4326) %>%
  st_transform(crs=3414)

june_2021_sf <- st_as_sf(june_2021, coords = c("longitude", "latitude"), crs = 4326) %>%
  st_transform(crs=3414)

hotels_sf <- st_as_sf(hotels, coords = c("Lng", "Lat"), crs = 4326) %>%
  st_transform(crs=3414)

tourism_sf <- st_as_sf(tourism, coords = c("Lng", "Lat"), crs = 4326) %>%
  st_transform(crs=3414)
```

## Geospatial and Aspatial Data Wrangling 

### Converting sf dataframes into sp Spatial Class

```{r}
mpsz <- as_Spatial(mpsz_sf)
sg <- as_Spatial(sg_sf)
train_services <-as_Spatial(train_services_sf)
june_2019 <- as_Spatial(june_2019_sf)
june_2021 <- as_Spatial(june_2021_sf)
hotels <- as_Spatial(hotels_sf)
tourism <- as_Spatial(tourism_sf)
```

Display the information about the Spatial Classes 

```{r}
mpsz
```

```{r}
sg
```

```{r}
train_services
```

```{r}
june_2019
```

```{r}
june_2021
```

```{r}
hotels
```

```{r}
tourism
```

### Converting the Spatial class into generic sp format

```{r}
mpsz_sp <- as(mpsz, "SpatialPolygons")
sg_sp <- as(sg, "SpatialPolygons")
train_services_sp <-as(train_services, "SpatialPoints")
june_2019_sp <- as(june_2019, "SpatialPoints")
june_2021_sp <- as(june_2021, "SpatialPoints")
hotels_sp <- as(hotels, "SpatialPoints")
tourism_sp <- as(tourism, "SpatialPoints")
```

Display the information about the sp objects

```{r}
mpsz_sp
```

```{r}
sg_sp
```

```{r}
train_services_sp
```

```{r}
june_2019_sp
```

```{r}
june_2021_sp
```

```{r}
hotels_sp
```

```{r}
tourism_sp
```

### Converting the sp objects into spatstat's ppp format

Difference between sp classes and ppp objects:

  - ppp objects include the boundary of the region where the point data have been observed, while sp classes do not

```{r}
train_services_ppp <-as(train_services_sp, "ppp")
june_2019_ppp <- as(june_2019_sp, "ppp")
june_2021_ppp <- as(june_2021_sp, "ppp")
hotels_ppp <- as(hotels_sp, "ppp")
tourism_ppp <- as(tourism_sp, "ppp")
```

Take a quick look at all the ppp objects summary information

```{r}
summary(train_services_ppp)
```

For *train_services_ppp* there are no duplicated points

```{r}
summary(june_2019_ppp)
```

For *june_2019_ppp* there are duplicated points

```{r}
summary(june_2021_ppp)
```

For *june_2021_ppp* there are duplicated points

```{r}
summary(hotels_ppp)
```

For *hotels_ppp* there are duplicated points

```{r}
summary(tourism_ppp)
```

For *tourism_ppp* there are duplicated points

From the above summaries, we can see that other than *train_services_ppp*, all the other ppp objects contain duplicated points.

### Handling duplicated points

Confirm that there are duplicated points in the ppp objects using the **any()** and **duplicated()** functions

```{r}
any(duplicated(train_services_ppp)) 
```

```{r}
any(duplicated(june_2019_ppp)) 
```

```{r}
any(duplicated(june_2021_ppp)) 
```

```{r}
any(duplicated(hotels_ppp)) 
```

```{r}
any(duplicated(tourism_ppp)) 
```

It is always unclear on how to handle duplicates with Spatial Point Pattern Analysis.

One of the major consideration is that, if we delete the duplicate points, we might ignore things such as repeat occurrences at a certain place. It will cause us to lost valuable data.

Therefore, we will make each point "unique" by adding an attribute to the data that contains duplicate points:

  - *june_2019_ppp*
  - *june_2021_ppp*
  - *hotels_ppp*
  - *tourism_ppp*

This method is calling **jittering**

```{r}
june_2019_ppp_jit <- rjitter(june_2019_ppp, 
                             retry=TRUE, 
                             nsim=1, 
                             drop=TRUE)

june_2021_ppp_jit <- rjitter(june_2021_ppp, 
                             retry=TRUE, 
                             nsim=1, 
                             drop=TRUE)

hotels_ppp_jit <- rjitter(hotels_ppp, 
                             retry=TRUE, 
                             nsim=1, 
                             drop=TRUE)

tourism_ppp_jit <- rjitter(tourism_ppp, 
                             retry=TRUE, 
                             nsim=1, 
                             drop=TRUE)
```

After using jitter to the duplicated points, we will check if the changes were effected.

```{r}
any(duplicated(june_2019_ppp_jit)) 
```

```{r}
any(duplicated(june_2021_ppp_jit)) 
```

```{r}
any(duplicated(hotels_ppp_jit)) 
```

```{r}
any(duplicated(tourism_ppp_jit)) 
```
## Creating an owin object

Point pattern is defined as a series of events in a given area or window of observation. Therefore, it is important to define the observation window or area.

sg_sp is the CoastalOutline of Singapore. This will be the observation window we will be using.

```{r}
sg_owin <- as(sg_sp, "owin")
```

Display the output object using plot()

```{r}
plot(sg_owin)
```


## Combine Spatial Point Events and owin object

We will extract events that are specific to Singapore.This events include:

  - Airbnb Listings in June 2019
  - Airbnb Listing in June 2021
  - Tourism Attractions
  - Hotel Locations
  - Train services

```{r}
june_2019_SG_ppp = june_2019_ppp_jit[sg_owin]

summary(june_2019_SG_ppp)
```

```{r}
june_2021_SG_ppp = june_2021_ppp_jit[sg_owin]

summary(june_2021_SG_ppp)
```

```{r}
tourism_SG_ppp = tourism_ppp_jit[sg_owin]

summary(tourism_SG_ppp)
```

```{r}
hotels_SG_ppp = hotels_ppp_jit[sg_owin]

summary(hotels_SG_ppp)
```

```{r}
train_services_SG_ppp = train_services_ppp[sg_owin]

summary(train_services_SG_ppp)
```

Visualise each of the newly derived ppp objects that are confined to Singapore's boundaries

```{r}
plot(june_2019_SG_ppp)
```

```{r}
plot(june_2021_SG_ppp)
```

```{r}
plot(tourism_SG_ppp)
```

```{r}
plot(hotels_SG_ppp)
```

```{r}
plot(train_services_SG_ppp)
```

# Exploratory Spatial Data Analysis

## Kernel Density Estimation

**We want to compute number of points per square kilometer**

### Convert the unit of measurement to kilometers 

Since SVY21 uses meters as a unit of measurement, we will convert it to kilometers using the rescale() function

```{r}
june_2019_SG_ppp_km <- rescale(june_2019_SG_ppp, 1000, 'km')
june_2021_SG_ppp_km <- rescale(june_2021_SG_ppp, 1000, 'km')
tourism_SG_ppp_km <- rescale(tourism_SG_ppp, 1000, 'km')
hotels_SG_ppp_km <- rescale(hotels_SG_ppp, 1000, 'km')
train_services_SG_ppp_km <- rescale(train_services_SG_ppp, 1000, 'km')
```

### Compute Kernel Density Estimation using automatic bandwidth selection method

```{r}
kde_june_2019_SG_bw <- density(june_2019_SG_ppp_km,
                              sigma=bw.ppl,
                              edge=TRUE,
                            kernel="gaussian") 

kde_june_2021_SG_bw <- density(june_2021_SG_ppp_km,
                              sigma=bw.ppl,
                              edge=TRUE,
                            kernel="gaussian")

kde_tourism_SG_bw <- density(tourism_SG_ppp_km,
                              sigma=bw.ppl,
                              edge=TRUE,
                            kernel="gaussian")

kde_hotels_SG_bw <- density(hotels_SG_ppp_km,
                              sigma=bw.ppl,
                              edge=TRUE,
                            kernel="gaussian")

kde_train_services_SG_bw <- density(train_services_SG_ppp_km,
                              sigma=bw.ppl,
                              edge=TRUE,
                            kernel="gaussian")
```

### Plot the Kernel Density Estimation for:
  - Airbnb Listings in June 2019
  - Airbnb Listing in June 2021
  - Tourism Attractions
  - Hotel Locations
  - Train services


```{r}
plot(kde_june_2019_SG_bw)
```

```{r}
plot(kde_june_2019_SG_bw)
```

```{r}
plot(kde_june_2021_SG_bw)
```

```{r}
plot(kde_tourism_SG_bw)
```

```{r}
plot(kde_hotels_SG_bw)
```

```{r}
plot(kde_train_services_SG_bw)
```

### Converting KDE output into RasterLayer Object

The steps taken will be:

  - Convert the KDE outputs into a SpatialGridDataFrame
  - Convert the SpatialGridDataFrame into RasterLayer objects

In order for us to use the tmap package to map the RasterLayer objects, we have to include the CRS information.

Since we rescaled the coordinates to kilometers earlier, we have to rescale it back to meters in order for it to match the SVY21's unit of measurement of meters.

```{r}

kde_june_2019_SG_bw_raster <- kde_june_2019_SG_bw %>% 
  rescale(., 0.001, "m") %>%
  as.SpatialGridDataFrame.im() %>% 
  raster()

kde_june_2021_SG_bw_raster <- kde_june_2021_SG_bw %>% 
  rescale(., 0.001, "m") %>%
  as.SpatialGridDataFrame.im() %>% 
  raster()

kde_hotels_SG_bw_raster <- kde_hotels_SG_bw %>% 
  rescale(., 0.001, "m") %>%
  as.SpatialGridDataFrame.im() %>% 
  raster()

kde_tourism_SG_bw_raster <- kde_tourism_SG_bw %>% 
  rescale(., 0.001, "m") %>%
  as.SpatialGridDataFrame.im() %>% 
  raster()

kde_train_services_SG_bw_raster <- kde_train_services_SG_bw %>% 
  rescale(., 0.001, "m") %>%
  as.SpatialGridDataFrame.im() %>% 
  raster()
```

Check the properties of the RasterLayer Objects

```{r}
kde_june_2019_SG_bw_raster
```


```{r}
kde_june_2021_SG_bw_raster
```


```{r}
kde_hotels_SG_bw_raster
```


```{r}
kde_tourism_SG_bw_raster
```


```{r}
kde_train_services_SG_bw_raster
```

From the above outputs, we can see that the CRS property of the RasterLayer Objects are NA.

### Assigning Projection Systems

Assign CRS 3414 to all the RasterLayer objects and check the outputs

```{r}
projection(kde_june_2019_SG_bw_raster) <- CRS('+init=EPSG:3414')
kde_june_2019_SG_bw_raster
```

```{r}
projection(kde_june_2021_SG_bw_raster) <- CRS('+init=EPSG:3414')
kde_june_2021_SG_bw_raster
```

```{r}
projection(kde_hotels_SG_bw_raster) <- CRS('+init=EPSG:3414')
kde_hotels_SG_bw_raster
```

```{r}
projection(kde_tourism_SG_bw_raster) <- CRS('+init=EPSG:3414')
kde_tourism_SG_bw_raster
```

```{r}
projection(kde_train_services_SG_bw_raster) <- CRS('+init=EPSG:3414')
kde_train_services_SG_bw_raster
```
Create a function to plot the Density Maps

```{r}
density_map <- function(raster_object, mtitle) {
  tm_basemap('OpenStreetMap') +
tm_shape(raster_object) +
  tm_raster('v') + 
  tm_layout(legend.position = c('right', 'bottom'), 
            frame = FALSE, 
            main.title = mtitle,
            main.title.position = 'center',
            main.title.size = 1)

} 

```


```{r}
june_2019_dmap <- density_map(kde_june_2019_SG_bw_raster, mtitle = "June 2019 SG Airbnb Listings Density Map")
june_2021_dmap <- density_map(kde_june_2021_SG_bw_raster, mtitle = "June 2021 SG Airbnb Listings Density Map")
hotels_dmap <- density_map(kde_hotels_SG_bw_raster, mtitle = "SG Hotels Density Map")
tourism_dmap <- density_map(kde_tourism_SG_bw_raster, mtitle = "SG Tourism Attractions Density Map")
train_services_dmap <- density_map(kde_train_services_SG_bw_raster, mtitle = "SG Train Services Density Map")
```

```{r}
june_2021_dmap
```

```{r}
hotels_dmap
```

```{r}
tourism_dmap
```

```{r}
train_services_dmap
```

## Kernel Density Map vs Point Map

There are a few advantages that Kernel Density Map has over Point Map.

  - Firstly, Kernel density z
  estimate smooths the points in a given area, creating a continuous surface of density estimations. However, point map only shows the inidividual points that are concentrated within an area, and only can be observed quantitatively.
  
  - Secondly, kernel density map makes use of the inverse-distance weighted counts of the points. These weighted counts are used to represent the concentration of points at a specific location. This feature of kernel density map is unable to be replicated using point map.



# Second-order Spatial Point Patterns Analysis

## Prepare specific subzones for analysis

Due to the intensive computational power needed to conduct Second Order Analysis on the whole of Singapore, we select only a few subzones for analysis

  - DOWNTOWN CORE
  - GEYLANG
  - JURONG WEST
  - NEWTON
  - HOUGANG 

```{r}
mpsz_sf$STUDY_AREA[(mpsz_sf$PLN_AREA_N=='DOWNTOWN CORE') | (mpsz_sf$PLN_AREA_N=='GEYLANG') | (mpsz_sf$PLN_AREA_N=='JURONG WEST') | (mpsz_sf$PLN_AREA_N=='NEWTON') | (mpsz_sf$PLN_AREA_N=='HOUGANG')] = "Y"
mpsz_sf$STUDY_AREA[is.na(mpsz_sf$STUDY_AREA)] = 'N'

tm_shape(mpsz_sf) +
  tm_fill('STUDY_AREA',
          palette = c('grey90', 'rosybrown2')) +
  tm_borders(col = 'gray28', lwd = 0.1, alpha = 0.3) +
    tm_layout(legend.show = FALSE,
              frame = FALSE)
```

## Extract and define study areas

5 subzones : DOWNTOWN CORE, GEYLANG, HOUGANG, JURONG WEST and NEWTON, will be extracted to perform analysis 

The steps taken to prepare the individual subzone data will be:

  - Extract individual subzone from the mpsz_sf
  - Convert the individual subzone data into an owin object
  
```{r}
get_owin <- function(subzone_data, pln_area_n) {
  subzone_data[subzone_data$PLN_AREA_N == pln_area_n,] %>%
    as('Spatial') %>%
    as('SpatialPolygons') %>%
    as('owin')
}
```

Create respective owin objects for individual subzones

```{r}
downtown_owin <- get_owin(mpsz_sf, "DOWNTOWN CORE")
geylang_owin <- get_owin(mpsz_sf, "GEYLANG")
hougang_owin <- get_owin(mpsz_sf, "HOUGANG")
jurongw_owin <- get_owin(mpsz_sf, "JURONG WEST")
newton_owin <- get_owin(mpsz_sf, "NEWTON")
```

Combine the owin objects with the Spatial Points

```{r}
downtown_2019_ppp <- june_2019_ppp[downtown_owin]
geylang_2019_ppp <- june_2019_ppp[geylang_owin]
hougang_2019_ppp <- june_2019_ppp[hougang_owin]
jurongw_2019_ppp <- june_2019_ppp[jurongw_owin]
newton_2019_ppp <- june_2019_ppp[newton_owin]
```

Visualise the ppp objects for checking, to ensure that they are error-free.

```{r}
par(mfrow=c(2,3))

plot(downtown_2019_ppp, main = 'Downtown Core')
plot(geylang_2019_ppp, main = 'Geylang')
plot(hougang_2019_ppp, main = 'Hougang')
plot(jurongw_2019_ppp , main = 'Jurong West')
plot(newton_2019_ppp , main = 'Newton')

mtext('Airbnb Listings in 2019', outer=TRUE, side=3, line=-12)
```

## Analaysis Formulation

Second Order Spatial Point Patterns Analysis will be conducted with Hypothesis Testing. 

We will be assessing if the point patterns is significantly different from Complete Spatial Randomness, which follows a Poisson Process. 

For the purpose of this analysis, we formulate the following:

  - Null Hypothesis : The distribution of the Airbnb Listings are randomly distributed
  - Alternative Hypothesis : The distribution of the Airbnb Listings are not randomly distributed
  - Significance level : 0.01
  - Confidence level : 99%
  

### L-function

The L-function is the function that will be used to conducted the Second-Order Analysis

### Create functions

This function below computes the l_estimate and plots it.

```{r}
l_estimate <- function(ppp_object) {
  l_est <- Lest(ppp_object, correction = "Ripley")
  
  plot(l_est, . -r ~ r, 
     ylab= "L(d)-r", xlab = "d(m)", main = 'L-estimate')
}
```

### Airbnb Listings 2019 in Downtown Core

Compute L function Estimate

```{r}
l_estimate(downtown_2019_ppp)
```

Performing Complete Spatial Randomness Test

  - Null Hypothesis : The distribution of the Airbnb Listings in Downtown Core during 2019 are randomly distributed
  - Alternative Hypothesis : The distribution of the Airbnb Listings in Downtown Core during 2019 are not randomly distributed
  - Significance level : 0.01
  - Confidence level : 99%

We will make use of Monte Carlo Simulation together with L-function for this analysis.

```{r}
plot(envelope(downtown_2019_ppp, Gest, nsim = 99))
```

### Airbnb Listings 2019 in Geylang

Compute L function Estimate

```{r}
l_estimate(geylang_2019_ppp)
```

Performing Complete Spatial Randomness Test

  - Null Hypothesis : The distribution of the Airbnb Listings in Downtown Core during 2019 are randomly distributed
  - Alternative Hypothesis : The distribution of the Airbnb Listings in Downtown Core during 2019 are not randomly distributed
  - Significance level : 0.01
  - Confidence level : 99%

We will make use of Monte Carlo Simulation together with L-function for this analysis.

```{r}
plot(envelope(geylang_2019_ppp, Gest, nsim = 99))
```


### Airbnb Listings 2019 in Hougang

Compute L function Estimate

```{r}
l_estimate(hougang_2019_ppp)
```

Performing Complete Spatial Randomness Test

  - Null Hypothesis : The distribution of the Airbnb Listings in Hougang during 2019 are randomly distributed
  - Alternative Hypothesis : The distribution of the Airbnb Listings in Hougang during 2019 are not randomly distributed
  - Significance level : 0.01
  - Confidence level : 99%

We will make use of Monte Carlo Simulation together with L-function for this analysis.

```{r}
plot(envelope(hougang_2019_ppp, Gest, nsim = 99))
```

### Airbnb Listings 2019 in Jurong West

Compute L function Estimate

```{r}
l_estimate(jurongw_2019_ppp)
```

Performing Complete Spatial Randomness Test

  - Null Hypothesis : The distribution of the Airbnb Listings in Jurong West during 2019 are randomly distributed
  - Alternative Hypothesis : The distribution of the Airbnb Listings in Jurong west during 2019 are not randomly distributed
  - Significance level : 0.01
  - Confidence level : 99%

We will make use of Monte Carlo Simulation together with L-function for this analysis.

```{r}
plot(envelope(jurongw_2019_ppp, Gest, nsim = 99))
```



Compute L function Estimate

```{r}
l_estimate(newton_2019_ppp)
```

Performing Complete Spatial Randomness Test

  - Null Hypothesis : The distribution of the Airbnb Listings in Newton during 2019 are randomly distributed
  - Alternative Hypothesis : The distribution of the Airbnb Listings in Newton during 2019 are not randomly distributed
  - Significance level : 0.01
  - Confidence level : 99%

We will make use of Monte Carlo Simulation together with L-function for this analysis.

```{r}
plot(envelope(newton_2019_ppp, Gest, nsim = 99))
```


# Marked Spatial Point Patterns Analysis

Marked Point Patterns not only have density of events as first-order properties, they also have associated marks across the area of study.

In this section of analysis, we are using the Room Type of the Airbnb Listings as the associated marks.

## Exploring the Airbnb 2019 and 2021 Listings

```{r}
str(june_2019)
```

```{r}
str(june_2021)
```

From the 2 above outputs, we can see that the Room Type is in the character data type. However, for Marked Spatial Point Analysis, the marked field (Room Type) must be in factor data type if its values are categorical.

## Convert Character Data type to Factor Data type

We will make use of the as.factor() function to convert the marked field, Room Type to the factor data type.

```{r}
june_2019@data$room_type <-as.factor(june_2019@data$room_type)

str(june_2019)
```


```{r}
june_2021@data$room_type <-as.factor(june_2021@data$room_type)

str(june_2021)
```

### Visualise the Airbnb Listings by Room Type in 2019

```{r}
tm_shape(mpsz_sf) +
  tm_borders(alpha = 0.5) +
tm_shape(june_2019) +
  tm_dots(col = 'room_type', size = 0.02) +
tm_facets(by="room_type")
```

### Visualise the Airbnb Listings by Room Type in 2021

```{r}
tm_shape(mpsz_sf) +
  tm_borders(alpha = 0.5) +
tm_shape(june_2021) +
  tm_dots(col = 'room_type', size = 0.02) +
tm_facets(by="room_type")
```


## Convert the SpatialPointsDataFrame into ppp objects

Steps Taken:

  - Convert the SpatialPointDataFrame into ppp objects
  - Use jittering to handle duplicated Spatial Points

The main difference between this new ppp objects and the previous ones is that the new one has marked fields

```{r}
june_2019_marked_ppp <- as(june_2019, "ppp") %>%
  rjitter(., retry=TRUE, nsim=1, drop=TRUE)

june_2021_marked_ppp <- as(june_2021, "ppp") %>%
  rjitter(., retry=TRUE, nsim=1, drop=TRUE)
```


## Extract and Combine Spatial Points with study areas

Similar to the previous section above, we will only conduct analysis on 5 specific areas, namely:

  - DOWNTOWN CORE
  - GEYLANG
  - JURONG WEST
  - NEWTON
  - HOUGANG 
  
*As a reminder, these are the areas we are focusing on*

```{r}
tm_shape(mpsz_sf) +
  tm_fill('STUDY_AREA',
          palette = c('grey90', 'rosybrown2')) +
  tm_borders(col = 'gray28', lwd = 0.1, alpha = 0.3) +
    tm_layout(legend.show = FALSE,
              frame = FALSE)
```

Here, we will combine the respective ppp objects with the owin objects that were created in the previous sections

```{r}
downtown_2019_marked_ppp <- june_2019_marked_ppp[downtown_owin]
geylang_2019_marked_ppp <- june_2019_marked_ppp[geylang_owin]
hougang_2019_marked_ppp <- june_2019_marked_ppp[hougang_owin]
jurongw_2019_marked_ppp <- june_2019_marked_ppp[jurongw_owin]
newton_2019_marked_ppp <- june_2019_marked_ppp[newton_owin]

downtown_2021_marked_ppp <- june_2021_marked_ppp[downtown_owin]
geylang_2021_marked_ppp <- june_2021_marked_ppp[geylang_owin]
hougang_2021_marked_ppp <- june_2021_marked_ppp[hougang_owin]
jurongw_2021_marked_ppp <- june_2021_marked_ppp[jurongw_owin]
newton_2021_marked_ppp <- june_2021_marked_ppp[newton_owin]
```

Visualise the ppp objects for checking, to ensure that they are error-free.

For Airbnb Listings by Room-Type in 2019

```{r}
par(mfrow=c(2,3))

plot(downtown_2019_marked_ppp, main = 'Downtown Core', which.marks = "room_type")
plot(geylang_2019_marked_ppp, main = 'Geylang', which.marks = "room_type")
plot(hougang_2019_marked_ppp, main = 'Hougang', which.marks = "room_type")
plot(jurongw_2019_marked_ppp , main = 'Jurong West', which.marks = "room_type")
plot(newton_2019_marked_ppp , main = 'Newton', which.marks = "room_type")

mtext('Airbnb Listings by Room-Type in 2019', outer=TRUE, side=3, line=-12)
```

For Airbnb Listings by Room-Type in 2021

```{r}
par(mfrow=c(2,3))

plot(downtown_2021_marked_ppp, main = 'Downtown Core', which.marks = "room_type")
plot(geylang_2021_marked_ppp, main = 'Geylang', which.marks = "room_type")
plot(hougang_2021_marked_ppp, main = 'Hougang', which.marks = "room_type")
plot(jurongw_2021_marked_ppp , main = 'Jurong West', which.marks = "room_type")
plot(newton_2021_marked_ppp , main = 'Newton', which.marks = "room_type")

mtext('Airbnb Listings by Room-Type in 2021', outer=TRUE, side=3, line=-12)
```

# First-Order Marked Spatial Point Patterns Analysis


```{r}
par(mfrow=c(5,3))

plot((density(split(rescale(downtown_2019_marked_ppp, 1000)))), main = 'Downtown Core')
plot((density(split(rescale(geylang_2019_marked_ppp, 1000)))), main = 'Geylang')
plot((density(split(rescale(hougang_2019_marked_ppp, 1000)))), main = 'Hougang')
plot((density(split(rescale(jurongw_2019_marked_ppp, 1000)))), main = 'Jurong West')
plot((density(split(rescale(newton_2019_marked_ppp, 1000)))), main = 'Newton')

```











