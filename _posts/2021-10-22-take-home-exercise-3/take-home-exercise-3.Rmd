---
title: "Take-Home Exercise 3"
description: |
  A short description of the post.
author:
  - name: Darryl Kwok
    url: https://example.com/darrylkwok
date: 10-22-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE, error = FALSE, fig.retina = 3, R.options = list(width = 60))
```


# Introduction

## Overview

## Installing relevant packages

```{r echo=TRUE, eval=TRUE}
packages = c('olsrr', 'corrplot', 'ggpubr', 'sf', 'spdep', 'GWmodel', 'tmap', 'tidyverse', 'httr', 'jsonlite', 'matrixStats', 'raster', 'geosphere', 'units')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

# Data 

## Geospatial Data Import and Preparation

```{r}
mpsz <- st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL") %>%
  st_transform(3414)
```

```{r}
childcare_sf <- st_read("data/geospatial/child-care-services-geojson.geojson") %>%
  st_transform(crs = 3414)
```

```{r}
eldercare_sf <- st_read(dsn="data/geospatial", layer = "ELDERCARE") %>% 
  st_transform(3414)
```

```{r}
mrtlrt_sf <- st_read(dsn="data/geospatial", layer = "MRTLRTStnPtt") %>% 
  st_transform(3414)
```

```{r}
parks_sf <- st_read("data/geospatial/parks-geojson.geojson")  %>% 
  st_transform(3414)
```

```{r}
kinder_sf <- st_read("data/geospatial/kindergartens-geojson.geojson") %>% 
  st_transform(3414)
```

```{r}
hawkers_sf <- st_read("data/geospatial/hawker-centres-geojson.geojson") %>% 
  st_transform(3414)
```

```{r}
supermkts_sf <- st_read("data/geospatial/supermarkets-geojson.geojson") %>% 
  st_transform(3414)
```

```{r}
busstops_sf <- st_read(dsn="data/geospatial", layer = "BusStop")%>% 
  st_transform(3414)
```

### Create a function to preprocess the geospatial datasets

The actions taken will be:

  - Ensure that the geometry is valid
  - Remove Duplicates

```{r}
geo_preprocess <- function(df, add_col) {
  df <- df[!duplicated(df[, add_col]), ] %>% 
    st_make_valid()
    
  return(df)
}
```

### Execute the Preprocessing function on the geospatial datasets

```{r}
mpsz <- geo_preprocess(mpsz, "geometry")
childcare_sf <- geo_preprocess(childcare_sf, "geometry")
eldercare_sf <- geo_preprocess(eldercare_sf, "ADDRESSPOS")
mrtlrt_sf <- geo_preprocess(mrtlrt_sf, "STN_NAME")
parks_sf <- geo_preprocess(parks_sf, "geometry")
kinder_sf <- geo_preprocess(kinder_sf, "geometry")
hawkers_sf <- geo_preprocess(hawkers_sf, "geometry")
supermkts_sf <- geo_preprocess(supermkts_sf, "geometry")
busstops_sf <- geo_preprocess(busstops_sf, "geometry")
```


## Aspatial Data Import and Preparation

We will make use of the read_csv function to read the resale flat prices that is obtained from data.gov.sg

```{r eval=FALSE}
resale_prices <- read_csv("data/aspatial/resale-flat-prices-jan-2019-to-sept-2020.csv")
```

Since there are occurrences of "ST." in the CSV file, we will replace the "ST." occurrences to "SAINT"

```{r eval=FALSE}
resale_prices$street_name <- gsub("ST\\.", "SAINT", resale_prices$street_name)
```



We can see that the data read in from the CSV file, does not contain any coordinates. Therefore we will have to perform geocoding.

### Create a Geocoding Function

This function calls the search function of the commonapi of OneMap. 

Since the search function of the API does not require a token, we will not use a token here. 

The steps taken are:

  - The function takes in 2 parameters, the block number and the street name.
  - We will concatenate the 2 parameters together to create an address variable.
  - This variable will be passed in as a search value in the query to the API.
  - After getting the response, we will convert the response to a text.
  - Then, convert the text into a dataframe using the fromJSON() package from jsonlite library.
  - The output only contains the X, Y coordinates.
  
```{r eval=FALSE}
geocode_addr <- function(block, street_name) {
  url <- "https://developers.onemap.sg/commonapi/search"
  
  search_addr <- paste(block, street_name, sep = " ")
  
  query <- list("searchVal" = search_addr, "returnGeom" = "Y", "getAddrDetails" = "N", "pageNum" = "1")
  
  res <- GET(url, query = query)
  
  jsonRespText<-content(res,as="text") 
  output <- fromJSON(jsonRespText)  %>% 
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)
  
  return(output)
}

```

```{r eval=FALSE}

resale_prices$LATITUDE <- 0
resale_prices$LONGITUDE <- 0

for  (i in 1:nrow(resale_prices)) {
  temp_output <- geocode_addr(resale_prices[i, 4], resale_prices[i, 5])
  
  resale_prices$LATITUDE[i] <- temp_output$results.LATITUDE
  resale_prices$LONGITUDE[i] <- temp_output$results.LONGITUDE
  
}
```


This function converts the actual remaining lease period from a string format to a double format

```{r eval=FALSE}
cal_remain_lease <- function(each_col) {
  entry_list <- unlist(strsplit(each_col, '\\s+')[[1]])
  
  if (length(entry_list) > 2) {
    years <- as.numeric(unlist(entry_list[1]))
    months <-as.numeric(unlist(entry_list[3]))
    total_dur <- years + round((months/12), 2)
  } else {
    years <- as.numeric(unlist(entry_list[1]))
    total_dur <- years
  }
  
  return(unlist(total_dur))
}
```

Calculate the remaining lease duration for each record

```{r eval=FALSE}
resale_prices$remaining_lease <- sapply(resale_prices$remaining_lease, cal_remain_lease)
```


## Create a Dataframe to store the Central Business District of Singapore

The Downtown Core is one of the central districts of Singapore. Located in the Marina Bay Area, in the SouthWest part of the country. 

After creating the dataframe, convert the dataframe into a sf object

```{r eval=FALSE}
lat <- 1.287953
long <- 103.851784
cbd_coor_sf <- data.frame(lat, long) %>%
  st_as_sf(., coords = c("long", "lat"), crs=4326) %>%
  st_transform(crs=3414)
```

## Define functions to generate new columns

This function is to find the distance to the nearest facility

```{r eval=FALSE}
prox_prep <- function(prim_df, sec_df, var_name) {
  dist_matrix <- st_distance(prim_df, sec_df) %>% 
    drop_units()
  prim_df[,var_name] <- rowMins(dist_matrix) 
  
  return(prim_df)
}
```

This function is to count the number of facility within a radius

```{r eval=FALSE}
num_prep <- function(prim_df, sec_df, radius, var_name) {
  dist_matrix <- st_distance(prim_df, sec_df) %>% 
    drop_units()

  dist_matrix <- data.frame(dist_matrix)
  prim_df[,var_name] <- rowSums(dist_matrix <= radius)
  
  return(prim_df)
}
```

Create Facility Proximity columns

```{r eval=FALSE}
resale_prices_sf <- prox_prep(resale_prices_sf, eldercare_sf, "PROX_ELDER") %>%
  prox_prep(., mrtlrt_sf, "PROX_MRTLRT") %>%
  prox_prep(., parks_sf, "PROX_PARK") %>% 
  prox_prep(., hawkers_sf, "PROX_HAWKER") %>%
  prox_prep(., cbd_coor_sf, "PROX_CBD") %>% 
  prox_prep(., supermkts_sf, "PROX_SPRMKTS")
```

Create number of Facilities columns

```{r eval=FALSE}
resale_prices_sf <- num_prep(resale_prices_sf, childcare_sf, 350, "NUM_CC") %>%
  num_prep(., kinder_sf, 350, "NUM_KINDER") %>%
  num_prep(., busstops_sf, 350, "NUM_BUSSTOPS")
```

In order to save time having to rerun the pre-processing functions again, we will write the dataframe to a csv and read in when we need it. 

*Note: This is done after all the preprocessing and creation of new columns*

**After writing the sf object to a shapefile, the column names will be truncated.**

```{r eval=FALSE}
st_write(resale_prices_sf, "data/final_resale_info.shp")
```

Read in the shapefile that contains all the information created earlier

```{r}
resale_prices_sf <- st_read(dsn="data", layer="final_resale_info")
```


Visualise the different columns of the resale_prices_sf

```{r}
glimpse(resale_prices_sf)
```

Here the truncated column names will be rename for a better understanding of the columns. 

```{r}
resale_prices_sf <- resale_prices_sf %>%
  rename(floor_area_sqm = flr_r_s,
         remaining_lease = rmnng_l,
         resale_price = rsl_prc,
         PROX_CBD = PROX_CB,
         PROX_ELDER = PROX_EL,
         PROX_MRTLRT = PROX_MR,
         PROX_PARK = PROX_PA,
         PROX_HAWKER = PROX_HA,
         PROX_SPRMRT = PROX_SP)
```

## Exploratory Data Analysis

EDA is done before any modeling or steps to get a better understanding of all the variables.


### Box Plots

#### Box Plot for the Resale Prices

Summary Statistics for Resale Prices

```{r}
summary(resale_prices_sf$resale_price)
```

Box plot for Resale Prices

```{r}
ggplot(resale_prices_sf, aes(x = '', y = resale_price)) +
  geom_boxplot() + 
  labs(x='', y='Resale Price') +
  theme_minimal()
```

  - It can be observed that there is 1 upper outlier of $1186888 for the Resale Price.
  - The median of the Resale Prices can be seen to be $405000

### Histograms

#### Create a function to plot the histogram for the variables

#### Distribution of the Resale Prices

```{r}
ggplot(resale_prices_sf, aes(x = resale_price)) + 
  geom_histogram(fill = 'darksalmon') +
  labs(title = "Distribution of Resale Prices",
       x = "Resale Prices",
       y = 'Frequency') +
  theme_minimal()
```

  - The distribution of the Resale Prices are right-skewed. 
  - Majority of the Resale prices range from $250000 to $500000

#### Distribution of the independent variables

The independent variables consists of:
  
  - floor_area_sqm
  - remaining_lease
  - Proximity to CBD
  - Proximity to Eldercare
  - Proximity to MRT/LRT
  - Proximity to Park
  - Proximity to Hawkers
  - Proximity to Supermarkets
  - Number of Childcares within 350m
  - Number of Kindergarten within 350m
  - Number of Bus stops within 350m

```{r}
AREA_SQM <- ggplot(resale_prices_sf, aes(x = floor_area_sqm)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

REMAIN_LEASE <- ggplot(resale_prices_sf, aes(x = remaining_lease)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_CBD <- ggplot(resale_prices_sf, aes(x = PROX_CBD)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_ELDER <- ggplot(resale_prices_sf, aes(x = PROX_ELDER)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_MRTLRT <- ggplot(resale_prices_sf, aes(x = PROX_MRTLRT)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_PARK <- ggplot(resale_prices_sf, aes(x = PROX_PARK)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_HAWKER <- ggplot(resale_prices_sf, aes(x = PROX_HAWKER)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_SPRMRT <- ggplot(resale_prices_sf, aes(x = PROX_SPRMRT)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

NUM_CC <- ggplot(resale_prices_sf, aes(x = NUM_CC)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

NUM_KIN <- ggplot(resale_prices_sf, aes(x = NUM_KIN)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

NUM_BUS <- ggplot(resale_prices_sf, aes(x = NUM_BUS)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

ggarrange(AREA_SQM, REMAIN_LEASE, PROX_CBD, PROX_ELDER, PROX_MRTLRT, PROX_PARK, PROX_HAWKER, PROX_SPRMRT, NUM_CC, NUM_KIN, NUM_BUS, ncol = 3, nrow = 4)
```


#### Top 10 Towns with the highest Resale Prices 

Create a new dataframe called **towns_avg**. This dataframe consists of the average Resale Price of each town.

*After calculating the average, rescale the resale price by dividing it by 100000. This is to ensure that the values are more easily understandable when plotted.*

```{r}
towns_avg <- aggregate(resale_prices_sf[,"resale_price"], list(resale_prices_sf$town), mean) %>%
  rename(town = Group.1)

towns_avg$resale_price <- sapply(towns_avg$resale_price, function(x) x/100000)
```

```{r}
top10_price = top_n(towns_avg, 10, resale_price)

ggplot(top10_price, aes(x=resale_price, y=reorder(town, resale_price), label=round(resale_price, 2))) +
  geom_col(fill='darksalmon') +
  labs(title='Top 10 Towns with the highest Average Resale Prices',
       x='Resale Price ($100000)',
       y='Town') +
  geom_text(nudge_x=0.01, colour='gray23', size=3.5) +
  theme_minimal()
```


#### Statistical Point Map

This is to reveal the geospatial distribution of the Resale Prices in Singapore.

```{r}
tmap_mode("view")

tm_shape(mpsz)+
  tm_polygons() +
tm_shape(resale_prices_sf) +  
  tm_dots(col = "resale_price",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")

```


# Regression

## Multiple Linear Regression Model

### Visualising the relationships of the independent variables

```{r}
var_list <- c("floor_area_sqm", "remaining_lease", "PROX_CBD", "PROX_ELDER", "PROX_MRTLRT", "PROX_PARK", "PROX_HAWKER", "PROX_SPRMRT", "NUM_CC", "NUM_KIN", "NUM_BUS")

resale_prices <- resale_prices_sf %>%
  st_drop_geometry()

corrplot(cor(resale_prices[, var_list]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

  - From above, we can observe that there are no 2 variables that are highly correlated with each other. Therefore, we will not remove any variables.

### Building the Multi-Linear Regression Model

```{r}
resale_mlr <- lm(formula = resale_price ~ floor_area_sqm + remaining_lease + PROX_CBD + PROX_ELDER + PROX_HAWKER + PROX_MRTLRT + PROX_PARK + PROX_SPRMRT + NUM_BUS + NUM_CC + NUM_KIN,  data = resale_prices_sf) 

summary(resale_mlr)
```

  - From the above report, it can be observed that all the independent variables are statistically significant. Therefore, we will proceed to keep all the variables for further analysis.
  

```{r}
ols_regress(resale_mlr)
```

## Testing the assumptions of Linear Regression 

### Multi-Collinearity Test

```{r}
ols_vif_tol(resale_mlr)
```

### Non-linearity Test

```{r}
ols_plot_resid_fit(resale_mlr)
```

### Normality Assumption Test

```{r}
ols_plot_resid_hist(resale_mlr)
```

### Spatial Autocorrelation Test

Since the hedonic model we are building are using geographically referenced attributes, it is important for us to visualise the residuals of the pricing model.

Retrieve the residuals of the pricing model and save it as a dataframe

```{r}
mlr_output <- as.data.frame(resale_mlr$residuals)
```

Then join the newly created dataframe to the resale_prices_sf

```{r}
resale_prices_res_sf <- cbind(resale_prices_sf, 
                        mlr_output) %>% 
  rename(MLR_RES = resale_mlr.residuals)
```

Since the **spdep** package can only be used to process sp conformed spatial data objects, we will convert the resale_prices_res_sg to Spatial Objects.

```{r}
resale_prices_res_sp <- as_Spatial(resale_prices_res_sf)

resale_prices_res_sp
```

After converting, we will use the tmap package to visualise the distribution of the residuals on an interactive map for a more in-depth analysis.

```{r}
tmap_mode("view")

tm_shape(mpsz)+
  tm_polygons(alpha = 0.4) +
tm_shape(resale_prices_res_sp) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")
```


Compute the distance-based weight matrix.

This will be performed by using dnearneigh function of the **spdep** function.

```{r}
nb <- dnearneigh(coordinates(resale_prices_res_sp), 0, 1500, longlat = FALSE)
```

We will then convert the output neighbours list into spatial weights

```{r}
nb_lw <- nb2listw(nb, style = "W")
```

Perform Moran's I test for residual spatial autocorrelation

```{r}
lm.morantest(resale_mlr, nb_lw)
```



## Regression with Geographic Weighted Regression Models

### Adaptive Bandwidth Geographic 

```{r}
bw_adaptive <- bw.gwr(formula = resale_price ~ floor_area_sqm + remaining_lease + PROX_CBD + PROX_ELDER + PROX_HAWKER + PROX_MRTLRT + PROX_PARK + PROX_SPRMRT + NUM_BUS + NUM_CC + NUM_KIN,  data = resale_prices_res_sp, approach="CV", kernel="gaussian", adaptive=TRUE, longlat=FALSE)
```

Construct the Geographic Weighted Regression Model

```{r}
gwr_adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm + remaining_lease + PROX_CBD + PROX_ELDER + PROX_HAWKER + PROX_MRTLRT + PROX_PARK + PROX_SPRMRT + NUM_BUS + NUM_CC + NUM_KIN,  data=resale_prices_res_sp, bw=bw_adaptive, kernel = 'gaussian', adaptive=TRUE, longlat = FALSE)

gwr_adaptive
```


## Visualising GWR Output

### Converting SDF into sf dataframe

```{r}
resale_prices_sf_adaptive <- st_as_sf(gwr_adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r}
tmap_mode("view")
tm_shape(mpsz)+
  tm_polygons(alpha = 0.1) +
tm_shape(resale_prices_sf_adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```



















