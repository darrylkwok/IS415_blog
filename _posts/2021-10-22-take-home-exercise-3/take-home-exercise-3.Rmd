---
title: "Take-Home Exercise 3"
description: |
  In this article, we will build hedonic pricing models to examine the effect of different factors such as proxmity to certain facilities and number of facilities within a certain radius. The hedonic pricing models will be built using Geographical Weighted Regression.
author:
  - name: Darryl Kwok
    url: https://example.com/darrylkwok
date: 10-22-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 4
    code_folding: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE, error = FALSE, fig.retina = 3, R.options = list(width = 60))
```


# Introduction

## Overview

## Installing relevant packages

```{r echo=TRUE, eval=TRUE}
packages = c('olsrr', 'corrplot', 'ggpubr', 'sf', 'spdep', 'GWmodel', 'tmap', 'tidyverse', 'httr', 'jsonlite', 'matrixStats', 'raster', 'geosphere', 'units')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

# Data 

The following datasets will be used for our analysis:

  - *resale-flat-prices-jan-2019-to-sept-2020*, a CSV file that contains the HDB Resale Flat Prices from Jan 2019 to Sept 2020. Downloaded from data.gov.sg but manually extracted the specific time period.
  - *MRTLRTStnPTT*, a Shapefile that contains location information of the Train Services in Singapore. Downloaded from LTA Data Mall
  - *MP14_SUBZONE_WEB_PL*, a Shapefile that contains the different subzone information in Singapore. Downloaded from data.gov.sg
  - *kindergartens-geojson*, a geojson file that contains the information of the kindergartens in Singapore. Downloaded from data.gov.sg
  - *ELDERCARE*, a shapefile that contains location information of the Elderly Care Services in Singapore. Downloaded from data.gov.sg
  - *BusStop"*, a shapefile that contains location information of the different Bus Stops in Singapore. Downloaded from LTA DataMall
  - *parks-geojson*, a geojson file that contains the location information of the different parks in Singapore. Downloaded from data.gov.sg
  - *supermarkets-geojson*, a geojson file that contains the location information of the different supermarkets in Singapore. Downloaded from data.gov.sg
  - *child-care-services-geojson*, a geojson file that contains the location information of the different childcare services in Singapore. Downloaded from data.gov.sg
  - *hawker-centres-geojson*, a geojson file that contains the location information of the different hawkers/foodcourts in Singapore. Downloaded from data.gov.sg


## Geospatial Data Import and Preparation

*MP14_SUBZONE_WEB_PL* is the URA Master Plan planning subzone boundaries.

```{r}
mpsz <- st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL") %>%
  st_transform(3414)
```

*child-care-services-geojson* is the geospatial information of the Childcare Services in Singapore.

```{r}
childcare_sf <- st_read("data/geospatial/child-care-services-geojson.geojson") %>%
  st_transform(crs = 3414)
```

*ELDERCARE* is the geospatial information of the Elderly Care Services in Singapore.

```{r}
eldercare_sf <- st_read(dsn="data/geospatial", layer = "ELDERCARE") %>% 
  st_transform(3414)
```

*MRTLRTStnPtt* is the geospatial information of the MRT and LRT Stations in Singapore.

```{r}
mrtlrt_sf <- st_read(dsn="data/geospatial", layer = "MRTLRTStnPtt") %>% 
  st_transform(3414)
```

*parks-geojson* is the geospatial information of the Parks in Singapore.

```{r}
parks_sf <- st_read("data/geospatial/parks-geojson.geojson")  %>% 
  st_transform(3414)
```

*kindergartens-geojson* is the geospatial information of the Kindergartens in Singapore.

```{r}
kinder_sf <- st_read("data/geospatial/kindergartens-geojson.geojson") %>% 
  st_transform(3414)
```

*hawker-centres-geojson* is the geospatial information of the Hawker Centres in Singapore.

```{r}
hawkers_sf <- st_read("data/geospatial/hawker-centres-geojson.geojson") %>% 
  st_transform(3414)
```

*supermarkets-geojson* is the geospatial information of the Supermarkets in Singapore.

```{r}
supermkts_sf <- st_read("data/geospatial/supermarkets-geojson.geojson") %>% 
  st_transform(3414)
```

*busStop* is the geospatial information of the BusStops in Singapore.

```{r}
busstops_sf <- st_read(dsn="data/geospatial", layer = "BusStop")%>% 
  st_transform(3414)
```

### Create a function to preprocess the geospatial datasets

The actions taken will be:

  - Ensure that the geometry is valid
  - Remove Duplicates

```{r}
geo_preprocess <- function(df, add_col) {
  df <- df[!duplicated(df[, add_col]), ] %>% 
    st_make_valid()
    
  return(df)
}
```

### Execute the Preprocessing function on the geospatial datasets

The Geospatial Pre-processing function will be executed on all the Geospatial Data imported.

```{r}
mpsz <- geo_preprocess(mpsz, "geometry")
childcare_sf <- geo_preprocess(childcare_sf, "geometry")
eldercare_sf <- geo_preprocess(eldercare_sf, "ADDRESSPOS")
mrtlrt_sf <- geo_preprocess(mrtlrt_sf, "STN_NAME")
parks_sf <- geo_preprocess(parks_sf, "geometry")
kinder_sf <- geo_preprocess(kinder_sf, "geometry")
hawkers_sf <- geo_preprocess(hawkers_sf, "geometry")
supermkts_sf <- geo_preprocess(supermkts_sf, "geometry")
busstops_sf <- geo_preprocess(busstops_sf, "geometry")
```


## Aspatial Data Import and Preparation

We will make use of the read_csv function to read the resale flat prices that is obtained from data.gov.sg

  - The CSV file contains the HDB resale prices from jan 2019 to sept 2020. 

```{r eval=FALSE}
resale_prices <- read_csv("data/aspatial/resale-flat-prices-jan-2019-to-sept-2020.csv")
```

Since there are occurrences of "ST." in the CSV file, we will replace the "ST." occurrences to "SAINT"

```{r eval=FALSE}
resale_prices$street_name <- gsub("ST\\.", "SAINT", resale_prices$street_name)
```



We can see that the data read in from the CSV file, does not contain any coordinates. Therefore we will have to perform geocoding.

### Create a Geocoding Function

This function calls the search function of the commonapi of OneMap. 

Since the search function of the API does not require a token, we will not use a token here. 

The steps taken are:

  - The function takes in 2 parameters, the block number and the street name.
  - We will concatenate the 2 parameters together to create an address variable.
  - This variable will be passed in as a search value in the query to the API.
  - After getting the response, we will convert the response to a text.
  - Then, convert the text into a dataframe using the fromJSON() package from jsonlite library.
  - The output only contains the X, Y coordinates.
  
```{r eval=FALSE}
geocode_addr <- function(block, street_name) {
  url <- "https://developers.onemap.sg/commonapi/search"
  
  search_addr <- paste(block, street_name, sep = " ")
  
  query <- list("searchVal" = search_addr, "returnGeom" = "Y", "getAddrDetails" = "N", "pageNum" = "1")
  
  res <- GET(url, query = query)
  
  jsonRespText<-content(res,as="text") 
  output <- fromJSON(jsonRespText)  %>% 
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)
  
  return(output)
}

```

Execute the Geocoding function defined above to all the rows within the dataset imported from **resale-flat-prices-jan-2019-to-sept-2020.csv** 

```{r eval=FALSE}

resale_prices$LATITUDE <- 0
resale_prices$LONGITUDE <- 0

for  (i in 1:nrow(resale_prices)) {
  temp_output <- geocode_addr(resale_prices[i, 4], resale_prices[i, 5])
  
  resale_prices$LATITUDE[i] <- temp_output$results.LATITUDE
  resale_prices$LONGITUDE[i] <- temp_output$results.LONGITUDE
  
}
```

This function converts the actual remaining lease period from a string format to a double format

Steps Taken:
  - Split the string within the remaining_lease column.
  - If the string length is 4, it contains months. Else it contains years only.
  - Output the final value as a double.

```{r eval=FALSE}
cal_remain_lease <- function(each_col) {
  entry_list <- unlist(strsplit(each_col, '\\s+')[[1]])
  
  if (length(entry_list) > 2) {
    years <- as.numeric(unlist(entry_list[1]))
    months <-as.numeric(unlist(entry_list[3]))
    total_dur <- years + round((months/12), 2)
  } else {
    years <- as.numeric(unlist(entry_list[1]))
    total_dur <- years
  }
  
  return(unlist(total_dur))
}
```

Calculate the remaining lease duration for each record by executing the function defined above.

```{r eval=FALSE}
resale_prices$remaining_lease <- sapply(resale_prices$remaining_lease, cal_remain_lease)
```


## Create a Dataframe to store the Central Business District of Singapore

The Downtown Core is one of the central districts of Singapore. Located in the Marina Bay Area, in the SouthWest part of the country. 

After creating the dataframe, convert the dataframe into a sf object

```{r eval=FALSE}
lat <- 1.287953
long <- 103.851784
cbd_coor_sf <- data.frame(lat, long) %>%
  st_as_sf(., coords = c("long", "lat"), crs=4326) %>%
  st_transform(crs=3414)
```

## Define functions to generate new columns

This function is to find the distance to the nearest facility

Steps Taken:
  - Make use of **st_distance** method to calculate the distances between all the HDBs and the facility in question.
  - A matrix will be generated from the function **st_function**
  - **rowMins** is used to get the shortest distance for each row within the matrix.

```{r eval=FALSE}
prox_prep <- function(prim_df, sec_df, var_name) {
  dist_matrix <- st_distance(prim_df, sec_df) %>% 
    drop_units()
  prim_df[,var_name] <- rowMins(dist_matrix) 
  
  return(prim_df)
}
```

This function is to count the number of facility within a radius

Steps Taken:
  - Make use of **st_distance** method to calculate the distances between all the HDBs and the facility in question.
  - Convert the matrix generated into a dataframe.
  - Filter out and count the number of facilities that are within a certain radius.

```{r eval=FALSE}
num_prep <- function(prim_df, sec_df, radius, var_name) {
  dist_matrix <- st_distance(prim_df, sec_df) %>% 
    drop_units()

  dist_matrix <- data.frame(dist_matrix)
  prim_df[,var_name] <- rowSums(dist_matrix <= radius)
  
  return(prim_df)
}
```

Create Facility Proximity columns

  - This is done by executing the **prox_prep()** function defined above.

```{r eval=FALSE}
resale_prices_sf <- prox_prep(resale_prices_sf, eldercare_sf, "PROX_ELDER") %>%
  prox_prep(., mrtlrt_sf, "PROX_MRTLRT") %>%
  prox_prep(., parks_sf, "PROX_PARK") %>% 
  prox_prep(., hawkers_sf, "PROX_HAWKER") %>%
  prox_prep(., cbd_coor_sf, "PROX_CBD") %>% 
  prox_prep(., supermkts_sf, "PROX_SPRMKTS")
```

Create number of Facilities columns

  - This is done by executing the **num_prep()** function defined above.

```{r eval=FALSE}
resale_prices_sf <- num_prep(resale_prices_sf, childcare_sf, 350, "NUM_CC") %>%
  num_prep(., kinder_sf, 350, "NUM_KINDER") %>%
  num_prep(., busstops_sf, 350, "NUM_BUSSTOPS")
```

In order to save time having to rerun the pre-processing functions again, we will write the dataframe to a csv and read in when we need it. 

*Note: This is done after all the preprocessing and creation of new columns*

**After writing the sf object to a shapefile, the column names will be truncated.**

```{r eval=FALSE}
st_write(resale_prices_sf, "data/final_resale_info.shp")
```

Read in the shapefile that contains all the information created earlier

  - This sf object contains all the geographical information of the HDBs as well as variables such as Proximity to a certain facility or the number of facilities within a certain radius of the HDB.

```{r}
resale_prices_sf <- st_read(dsn="data", layer="final_resale_info")
```


Visualise the different columns of the resale_prices_sf

```{r}
glimpse(resale_prices_sf)
```

Here the truncated column names will be rename for a better understanding of the columns. 

  - After pre-processing, we save the sf object as a shapefile. In the process of doing that, most of the column names are truncated. Therefore, we are renaming them in order to better understand the columns.

```{r}
resale_prices_sf <- resale_prices_sf %>%
  rename(floor_area_sqm = flr_r_s,
         remaining_lease = rmnng_l,
         resale_price = rsl_prc,
         PROX_CBD = PROX_CB,
         PROX_ELDER = PROX_EL,
         PROX_MRTLRT = PROX_MR,
         PROX_PARK = PROX_PA,
         PROX_HAWKER = PROX_HA,
         PROX_SPRMRT = PROX_SP)
```

## Exploratory Data Analysis

EDA is done before any modeling or steps to get a better understanding of all the variables.


### Box Plots

#### Box Plot for the Resale Prices

Summary Statistics for Resale Prices

```{r}
summary(resale_prices_sf$resale_price)
```

Box plot for Resale Prices

```{r}
ggplot(resale_prices_sf, aes(x = '', y = resale_price)) +
  geom_boxplot() + 
  labs(x='', y='Resale Price') +
  theme_minimal()
```

  - It can be observed that there is 1 upper outlier of $1186888 for the Resale Price.
  - The median of the Resale Prices can be seen to be $405000

### Histograms

#### Create a function to plot the histogram for the variables

#### Distribution of the Resale Prices

```{r}
ggplot(resale_prices_sf, aes(x = resale_price)) + 
  geom_histogram(fill = 'darksalmon') +
  labs(title = "Distribution of Resale Prices",
       x = "Resale Prices",
       y = 'Frequency') +
  theme_minimal()
```

  - The distribution of the Resale Prices are right-skewed. 
  - Majority of the Resale prices range from $250000 to $500000

#### Distribution of the independent variables

The independent variables consists of:
  
  - floor_area_sqm
  - remaining_lease
  - Proximity to CBD
  - Proximity to Eldercare
  - Proximity to MRT/LRT
  - Proximity to Park
  - Proximity to Hawkers
  - Proximity to Supermarkets
  - Number of Childcares within 350m
  - Number of Kindergarten within 350m
  - Number of Bus stops within 350m

```{r}
AREA_SQM <- ggplot(resale_prices_sf, aes(x = floor_area_sqm)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

REMAIN_LEASE <- ggplot(resale_prices_sf, aes(x = remaining_lease)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_CBD <- ggplot(resale_prices_sf, aes(x = PROX_CBD)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_ELDER <- ggplot(resale_prices_sf, aes(x = PROX_ELDER)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_MRTLRT <- ggplot(resale_prices_sf, aes(x = PROX_MRTLRT)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_PARK <- ggplot(resale_prices_sf, aes(x = PROX_PARK)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_HAWKER <- ggplot(resale_prices_sf, aes(x = PROX_HAWKER)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

PROX_SPRMRT <- ggplot(resale_prices_sf, aes(x = PROX_SPRMRT)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

NUM_CC <- ggplot(resale_prices_sf, aes(x = NUM_CC)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

NUM_KIN <- ggplot(resale_prices_sf, aes(x = NUM_KIN)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

NUM_BUS <- ggplot(resale_prices_sf, aes(x = NUM_BUS)) + 
  geom_histogram(bins=20, fill = 'lightblue') +
  theme_minimal()

ggarrange(AREA_SQM, REMAIN_LEASE, PROX_CBD, PROX_ELDER, PROX_MRTLRT, PROX_PARK, PROX_HAWKER, PROX_SPRMRT, NUM_CC, NUM_KIN, NUM_BUS, ncol = 3, nrow = 4)
```


#### Top 10 Towns with the highest Resale Prices 

Create a new dataframe called **towns_avg**. This dataframe consists of the average Resale Price of each town.

*After calculating the average, rescale the resale price by dividing it by 100000. This is to ensure that the values are more easily understandable when plotted.*

```{r}
towns_avg <- aggregate(resale_prices_sf[,"resale_price"], list(resale_prices_sf$town), mean) %>%
  rename(town = Group.1)

towns_avg$resale_price <- sapply(towns_avg$resale_price, function(x) x/100000)
```

```{r}
top10_price = top_n(towns_avg, 10, resale_price)

ggplot(top10_price, aes(x=resale_price, y=reorder(town, resale_price), label=round(resale_price, 2))) +
  geom_col(fill='darksalmon') +
  labs(title='Top 10 Towns with the highest Average Resale Prices',
       x='Resale Price ($100000)',
       y='Town') +
  geom_text(nudge_x=0.01, colour='gray23', size=3.5) +
  theme_minimal()
```

  - From the above plot, we can see that the average HDB resale prices are the highest in Central Area with Queenstown's prices not far behind.
  - This could be due to the fact that these are considered prime and central locations in Singapore.


#### Statistical Point Map

This is to reveal the Geospatial distribution of the Resale Prices in Singapore.

```{r}
tmap_mode("view")

tm_shape(mpsz)+
  tm_polygons() +
tm_shape(resale_prices_sf) +  
  tm_dots(col = "resale_price",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")

```

  - From the above plot, we can see that the prices around the Central Area of Singapore has the darkest colors. This means that the HDB resale prices are generally higher in those areas.

# Regression

## Multiple Linear Regression Model

### Visualising the relationships of the independent variables

By visualising the relationships of the independent variables in a correlation heatmap allows us to remove highly correlated variables that will affect the accuracy of the subsequent regression models that we will build.

```{r}
var_list <- c("floor_area_sqm", "remaining_lease", "PROX_CBD", "PROX_ELDER", "PROX_MRTLRT", "PROX_PARK", "PROX_HAWKER", "PROX_SPRMRT", "NUM_CC", "NUM_KIN", "NUM_BUS")

resale_prices <- resale_prices_sf %>%
  st_drop_geometry()

corrplot(cor(resale_prices[, var_list]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

  - From above, we can observe that there are no 2 variables that are highly correlated with each other. Therefore, we will not remove any variables.

### Building the Multi-Linear Regression Model

```{r}
resale_mlr <- lm(formula = resale_price ~ floor_area_sqm + remaining_lease + PROX_CBD + PROX_ELDER + PROX_HAWKER + PROX_MRTLRT + PROX_PARK + PROX_SPRMRT + NUM_BUS + NUM_CC + NUM_KIN,  data = resale_prices_sf) 

summary(resale_mlr)
```

  - From the above report, it can be observed that all the independent variables are statistically significant. Therefore, we will proceed to keep all the variables for further analysis.
  

```{r}
ols_regress(resale_mlr)
```

## Testing the assumptions of Linear Regression 

In order for us to perform regression on geographical data, we must first make sure that the 4 assumptions are met.

  - The residuals are uncorrelated with each other
  - The relationship between the dependent variable and independent variables are approximately linear
  - The residuals are assumed to be normally distributed.
  - Test for spatial autocorrelation to see if the points are correlated.

### Multi-Collinearity Test

```{r}
ols_vif_tol(resale_mlr)
```

  - From the above plot, we can see that since all the VIF values are below 10, there are no sign of multi-collineaity among the independent variables.

### Non-linearity Test

```{r}
ols_plot_resid_fit(resale_mlr)
```

  - Since majority of the points are scattered close to the red line, we can conclude that the relationships between the dependent variable and the independent variables are linear.

### Normality Assumption Test

```{r}
ols_plot_resid_hist(resale_mlr)
```

  - The plot above shows that the distribution of the residuals resemble normal distribution.

### Spatial Autocorrelation Test

Since the hedonic model we are building are using geographically referenced attributes, it is important for us to visualise the residuals of the pricing model.

Retrieve the residuals of the pricing model and save it as a dataframe

```{r}
mlr_output <- as.data.frame(resale_mlr$residuals)
```

Then join the newly created dataframe to the resale_prices_sf

```{r}
resale_prices_res_sf <- cbind(resale_prices_sf, 
                        mlr_output) %>% 
  rename(MLR_RES = resale_mlr.residuals)
```

Since the **spdep** package can only be used to process sp conformed spatial data objects, we will convert the resale_prices_res_sg to Spatial Objects.

```{r}
resale_prices_res_sp <- as_Spatial(resale_prices_res_sf)

resale_prices_res_sp
```

After converting, we will use the tmap package to visualise the distribution of the residuals on an interactive map for a more in-depth analysis.

```{r}
tmap_mode("view")

tm_shape(mpsz)+
  tm_polygons(alpha = 0.4) +
tm_shape(resale_prices_res_sp) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")
```


Compute the distance-based weight matrix.

This will be performed by using dnearneigh function of the **spdep** function.

```{r}
nb <- dnearneigh(coordinates(resale_prices_res_sp), 0, 1500, longlat = FALSE)
```

We will then convert the output neighbours list into spatial weights

```{r}
nb_lw <- nb2listw(nb, style = "W")
```

Perform Moran's I test for residual spatial autocorrelation

```{r}
lm.morantest(resale_mlr, nb_lw)
```



## Regression with Geographic Weighted Regression Models

### Adaptive Bandwidth Geographic 

```{r}
bw_adaptive <- bw.gwr(formula = resale_price ~ floor_area_sqm + remaining_lease + PROX_CBD + PROX_ELDER + PROX_HAWKER + PROX_MRTLRT + PROX_PARK + PROX_SPRMRT + NUM_BUS + NUM_CC + NUM_KIN,  data = resale_prices_res_sp, approach="CV", kernel="gaussian", adaptive=TRUE, longlat=FALSE)
```

  - From the above output, we can see that the recommended data points is 55. 
  - We will then pass this Bandwidth value in generating out Geographic Weighted Regression Model.

Construct the Geographic Weighted Regression Model

```{r}
gwr_adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm + remaining_lease + PROX_CBD + PROX_ELDER + PROX_HAWKER + PROX_MRTLRT + PROX_PARK + PROX_SPRMRT + NUM_BUS + NUM_CC + NUM_KIN,  data=resale_prices_res_sp, bw=bw_adaptive, kernel = 'gaussian', adaptive=TRUE, longlat = FALSE)

gwr_adaptive
```


## Visualising GWR Output

In order to better understand the Geographic Weighted Regression Model's output, we will visualise it.

### Converting SDF into sf dataframe

```{r}
resale_prices_sf_adaptive <- st_as_sf(gwr_adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r}
tmap_mode("view")
tm_shape(mpsz)+
  tm_polygons(alpha = 0.1) +
tm_shape(resale_prices_sf_adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

  - From the above plot, we can see that majority of the R-squared are in the 0.6 to 1 region. This means that most of the HDB Resale Prices are explained by the GWR Model. 














